{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook goal\n",
    "See if xarray could be a good way of storing our data.\n",
    "The nice thing is that it can handle multidimensional arrays\n",
    "while retaining meta data information.\n",
    "\n",
    "# Notebook conclusions\n",
    "this looks pretty good. we can store both deaths and confirmed cases in the\n",
    "xr.Dataset structure. It's a labeled 3D array. In addition, we can add\n",
    "any metadata from the separate ancillary files we would like."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from src.utils.paths import get_parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "pdir = get_parent_dir(2)\n",
    "\n",
    "def read_csse2df(path):\n",
    "    \"\"\"\n",
    "    Preliminary reader for CSSE time series data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        path to .csv file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        CSSE timeseries data with county FIPS codes as cols.\n",
    "    \"\"\"\n",
    "    # TODO: replace usage with class above, then delete\n",
    "    df = pd.read_csv(path, index_col=[0])\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read CSSE timeseries data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "csse_dir = os.path.join(pdir, 'data', 'processed', 'csse', 'US')\n",
    "\n",
    "fname_confirmed = \"time_series_covid19_confirmed_US_timeseries.csv\"\n",
    "fname_deaths = \"time_series_covid19_deaths_US_timeseries.csv\"\n",
    "\n",
    "path_confirmed = os.path.join(csse_dir, fname_confirmed)\n",
    "path_deaths = os.path.join(csse_dir, fname_deaths)\n",
    "\n",
    "ts_confirmed = read_csse2df(path_confirmed)\n",
    "ts_deaths = read_csse2df(path_deaths)\n",
    "\n",
    "ts_confirmed.index.name = 'time'\n",
    "ts_deaths.index.name = 'time'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "cheap temporary solutions for renaming the problematic \"Unnamed: ...\" columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# ts_confirmed\n",
    "search = np.array([\"Unnamed\" in x for x in ts_confirmed.columns.values])\n",
    "cols = ts_confirmed.columns[search].values\n",
    "\n",
    "coldict = {}\n",
    "for col in cols:\n",
    "    coldict[col] = [int(s) for s in col.split() if s.isdigit()][0]\n",
    "\n",
    "ts_confirmed = ts_confirmed.rename(columns=coldict)\n",
    "ts_confirmed.columns = pd.to_numeric(ts_confirmed.columns,\n",
    "                                     downcast='integer')\n",
    "\n",
    "# ts_deaths\n",
    "search = np.array([\"Unnamed\" in x for x in ts_deaths.columns.values])\n",
    "cols = ts_deaths.columns[search].values\n",
    "\n",
    "coldict = {}\n",
    "for col in cols:\n",
    "    coldict[col] = [int(s) for s in col.split() if s.isdigit()][0]\n",
    "\n",
    "ts_deaths = ts_deaths.rename(columns=coldict)\n",
    "ts_deaths.columns = pd.to_numeric(ts_deaths.columns,\n",
    "                                  downcast='integer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# diffs in cols or index?\n",
    "assert np.alltrue(ts_confirmed.columns == ts_deaths.columns)\n",
    "assert np.alltrue(ts_confirmed.index == ts_deaths.index)\n",
    "\n",
    "# create coord vars\n",
    "times = ts_confirmed.index.values\n",
    "locs = ts_confirmed.columns.values\n",
    "\n",
    "# create dims\n",
    "dims=['time', 'county']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "lets try a DataArray object"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (time: 111, county: 3252)>\n",
      "array([[  0,   0,   0, ...,   0,   0,   0],\n",
      "       [  0,   0,   0, ...,   0,   0,   0],\n",
      "       [  0,   0,   0, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  0, 151,  16, ...,   0,   0, 103],\n",
      "       [  0, 151,  16, ...,   0,   0, 103],\n",
      "       [  0, 151,  19, ...,   0,   0, 103]])\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2020-01-22 2020-01-23 ... 2020-05-11\n",
      "  * county   (county) int64 60 66 69 72 78 ... 90053 90054 90055 90056 99999\n"
     ]
    }
   ],
   "source": [
    "da = xr.DataArray(data=ts_confirmed.values,\n",
    "                  coords=[times, locs],\n",
    "                  dims=dims)\n",
    "print(da)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "lets try a Dataset object"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data_vars = {'confirmed': (dims, ts_confirmed.values),\n",
    "             'deaths': (dims, ts_deaths.values)}\n",
    "coords = {'time': times,\n",
    "          'county': locs}\n",
    "ds = xr.Dataset(data_vars=data_vars,\n",
    "                coords=coords)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df_deaths = ds.deaths.to_dataframe().reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df_deaths.to_feather(\"test.feather\")\n",
    "df_deaths.to_pickle(\"test.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-3837c9a2",
   "language": "python",
   "display_name": "PyCharm (bd4pp)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}